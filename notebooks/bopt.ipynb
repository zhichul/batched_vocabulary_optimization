{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050fcd42-90df-4edc-8f97-1faff9dc09f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bopt.core.tokenizer import Tokenizer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee1905c8-7f12-4185-9727-2cea333e081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\"[PAD]\", \"h\",\"a\",\"t\",\"e\", \"at\", \"hat\", \"ate\", \"hate\", \"b\", \"ab\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a2d999-0765-4149-9cde-9a97948a05d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = {\n",
    "    \"[PAD]\":0.0,\n",
    "    \"h\":0.0,\n",
    "    \"a\":0.0,\n",
    "    \"t\":0.0,\n",
    "    \"e\":math.log(1.0),\n",
    "    \"at\": math.log(2.0), \n",
    "    \"hat\": math.log(3.0), \n",
    "    \"ate\": math.log(4.0), \n",
    "    \"hate\": math.log(5.0),\n",
    "    \"b\": 0.0,\n",
    "    \"ab\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88a9dd5-0e6c-4a25-a9fc-f636e386bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab=vocab, weights=weight, continuing_subword_prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121c8c58-5776-4a7b-9ec3-cf9ddf535112",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 4\n",
    "e,la, c = tokenizer.forward(*tokenizer.encode_batch([\"hat\", \"hate\",  \"ab\", \"at\"], M=M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89a3612-508c-4b2f-9e15-13276f7a2877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(   h ->    h)  1.0 [   h ->   ha]      [   h ->  hat]      [   h -> hate]      [   h ->    a] 0.14 [   h ->   at] 0.29 [   h ->  ate] 0.57 [   h ->    t] 0.14 [   h ->   te]      [   h ->    e] 0.43 \n",
      "[  ha ->    h]      (  ha ->   ha)      [  ha ->  hat]      [  ha -> hate]      [  ha ->    a]      [  ha ->   at]      [  ha ->  ate]      [  ha ->    t]      [  ha ->   te]      [  ha ->    e]      \n",
      "[ hat ->    h]      [ hat ->   ha]      ( hat ->  hat)  1.0 [ hat -> hate]      [ hat ->    a]      [ hat ->   at]      [ hat ->  ate]      [ hat ->    t]      [ hat ->   te]      [ hat ->    e]  1.0 \n",
      "[hate ->    h]      [hate ->   ha]      [hate ->  hat]      (hate -> hate)  1.0 [hate ->    a]      [hate ->   at]      [hate ->  ate]      [hate ->    t]      [hate ->   te]      [hate ->    e]      \n",
      "[   a ->    h]  1.0 [   a ->   ha]      [   a ->  hat]      [   a -> hate]      (   a ->    a)  1.0 [   a ->   at]      [   a ->  ate]      [   a ->    t]  1.0 [   a ->   te]      [   a ->    e]  1.0 \n",
      "[  at ->    h]  1.0 [  at ->   ha]      [  at ->  hat]      [  at -> hate]      [  at ->    a]      (  at ->   at)  1.0 [  at ->  ate]      [  at ->    t]      [  at ->   te]      [  at ->    e]  1.0 \n",
      "[ ate ->    h]  1.0 [ ate ->   ha]      [ ate ->  hat]      [ ate -> hate]      [ ate ->    a]      [ ate ->   at]      ( ate ->  ate)  1.0 [ ate ->    t]      [ ate ->   te]      [ ate ->    e]      \n",
      "[   t ->    h]  1.0 [   t ->   ha]      [   t ->  hat]      [   t -> hate]      [   t ->    a]  1.0 [   t ->   at]      [   t ->  ate]      (   t ->    t)  1.0 [   t ->   te]      [   t ->    e]  1.0 \n",
      "[  te ->    h]      [  te ->   ha]      [  te ->  hat]      [  te -> hate]      [  te ->    a]      [  te ->   at]      [  te ->  ate]      [  te ->    t]      (  te ->   te)      [  te ->    e]      \n",
      "[   e ->    h]  0.5 [   e ->   ha]      [   e ->  hat]  0.5 [   e -> hate]      [   e ->    a] 0.17 [   e ->   at] 0.33 [   e ->  ate]      [   e ->    t] 0.17 [   e ->   te]      (   e ->    e)  1.0 \n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate([\"h\", \"ha\", \"hat\", \"hate\", \"a\", \"at\", \"ate\", \"t\", \"te\", \"e\"]):\n",
    "    for j, y in enumerate([\"h\", \"ha\", \"hat\", \"hate\", \"a\", \"at\", \"ate\", \"t\", \"te\", \"e\"]):\n",
    "        attention = math.exp(c[1,i,j].item())\n",
    "        attention_str = str(round(attention,2)) if attention > 0 else \"\"\n",
    "        if i == j:\n",
    "            print(f\"({x:>4} -> {y:>4}) {attention_str:>4}\", end=\" \")\n",
    "        else:\n",
    "            print(f\"[{x:>4} -> {y:>4}] {attention_str:>4}\", end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113361b1-be9f-4c3b-b29b-1cd6256974ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3\n",
    "e,la, c = tokenizer.forward(*tokenizer.encode_batch([\"hat\", \"hate\",  \"ab\", \"at\"], M=M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "351fea88-0294-485c-abf1-dc7bde024e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(   h ->    h)  1.0 [   h ->   ha]      [   h ->  hat]      [   h ->    a] 0.14 [   h ->   at] 0.29 [   h ->  ate] 0.57 [   h ->    t] 0.14 [   h ->   te]      [   h ->    e] 0.43 \n",
      "[  ha ->    h]      (  ha ->   ha)      [  ha ->  hat]      [  ha ->    a]      [  ha ->   at]      [  ha ->  ate]      [  ha ->    t]      [  ha ->   te]      [  ha ->    e]      \n",
      "[ hat ->    h]      [ hat ->   ha]      ( hat ->  hat)  1.0 [ hat ->    a]      [ hat ->   at]      [ hat ->  ate]      [ hat ->    t]      [ hat ->   te]      [ hat ->    e]  1.0 \n",
      "[   a ->    h]  1.0 [   a ->   ha]      [   a ->  hat]      (   a ->    a)  1.0 [   a ->   at]      [   a ->  ate]      [   a ->    t]  1.0 [   a ->   te]      [   a ->    e]  1.0 \n",
      "[  at ->    h]  1.0 [  at ->   ha]      [  at ->  hat]      [  at ->    a]      (  at ->   at)  1.0 [  at ->  ate]      [  at ->    t]      [  at ->   te]      [  at ->    e]  1.0 \n",
      "[ ate ->    h]  1.0 [ ate ->   ha]      [ ate ->  hat]      [ ate ->    a]      [ ate ->   at]      ( ate ->  ate)  1.0 [ ate ->    t]      [ ate ->   te]      [ ate ->    e]      \n",
      "[   t ->    h]  1.0 [   t ->   ha]      [   t ->  hat]      [   t ->    a]  1.0 [   t ->   at]      [   t ->  ate]      (   t ->    t)  1.0 [   t ->   te]      [   t ->    e]  1.0 \n",
      "[  te ->    h]      [  te ->   ha]      [  te ->  hat]      [  te ->    a]      [  te ->   at]      [  te ->  ate]      [  te ->    t]      (  te ->   te)      [  te ->    e]      \n",
      "[   e ->    h]  0.5 [   e ->   ha]      [   e ->  hat]  0.5 [   e ->    a] 0.17 [   e ->   at] 0.33 [   e ->  ate]      [   e ->    t] 0.17 [   e ->   te]      (   e ->    e)  1.0 \n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate([\"h\", \"ha\", \"hat\", \"a\", \"at\", \"ate\", \"t\", \"te\", \"e\"]):\n",
    "    for j, y in enumerate([\"h\", \"ha\", \"hat\", \"a\", \"at\", \"ate\", \"t\", \"te\", \"e\"]):\n",
    "        attention = math.exp(c[1,i,j].item())\n",
    "        attention_str = str(round(attention,2)) if attention > 0 else \"\"\n",
    "        if i == j:\n",
    "            print(f\"({x:>4} -> {y:>4}) {attention_str:>4}\", end=\" \")\n",
    "        else:\n",
    "            print(f\"[{x:>4} -> {y:>4}] {attention_str:>4}\", end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddd449bd-7bfb-4ce6-9a4c-57f47b71fc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000],\n",
       "        [ 0.1591],\n",
       "        [ 0.1301],\n",
       "        [ 0.1301],\n",
       "        [ 0.0000],\n",
       "        [ 0.0145],\n",
       "        [-0.0530],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.zero_grad()\n",
    "e[0].backward(retain_graph=True)\n",
    "tokenizer.weights.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8280392-7622-4709-8544-5d117480981e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000],\n",
       "        [ 0.0228],\n",
       "        [ 0.1023],\n",
       "        [ 0.1023],\n",
       "        [ 0.1454],\n",
       "        [ 0.0330],\n",
       "        [-0.0076],\n",
       "        [-0.0364],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.zero_grad()\n",
    "e[1].backward(retain_graph=True)\n",
    "tokenizer.weights.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69bf7581-bcbd-4c80-869a-fcbf4e428069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [-0.0408],\n",
       "        [-0.0408],\n",
       "        [ 0.1633],\n",
       "        [ 0.1020],\n",
       "        [ 0.0000],\n",
       "        [-0.0408],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.zero_grad()\n",
    "c.exp()[1][0][4].backward(retain_graph=True)\n",
    "tokenizer.weights.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8eaeb5cf-4e98-43c1-8944-f975d29247bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 2\n",
    "e,la, c =  tokenizer.forward(*tokenizer.encode_batch([\"hat\", \"hate\",  \"ab\", \"at\"], M=M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e19ad32-92cb-4e47-9f22-2fef94dbd029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(   h ->    h)  1.0 [   h ->   ha]      [   h ->    a] 0.33 [   h ->   at] 0.67 [   h ->    t] 0.33 [   h ->   te]      [   h ->    e]  1.0 \n",
      "[  ha ->    h]      (  ha ->   ha)      [  ha ->    a]      [  ha ->   at]      [  ha ->    t]      [  ha ->   te]      [  ha ->    e]      \n",
      "[   a ->    h]  1.0 [   a ->   ha]      (   a ->    a)  1.0 [   a ->   at]      [   a ->    t]  1.0 [   a ->   te]      [   a ->    e]  1.0 \n",
      "[  at ->    h]  1.0 [  at ->   ha]      [  at ->    a]      (  at ->   at)  1.0 [  at ->    t]      [  at ->   te]      [  at ->    e]  1.0 \n",
      "[   t ->    h]  1.0 [   t ->   ha]      [   t ->    a]  1.0 [   t ->   at]      (   t ->    t)  1.0 [   t ->   te]      [   t ->    e]  1.0 \n",
      "[  te ->    h]      [  te ->   ha]      [  te ->    a]      [  te ->   at]      [  te ->    t]      (  te ->   te)      [  te ->    e]      \n",
      "[   e ->    h]  1.0 [   e ->   ha]      [   e ->    a] 0.33 [   e ->   at] 0.67 [   e ->    t] 0.33 [   e ->   te]      (   e ->    e)  1.0 \n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate([\"h\", \"ha\", \"a\", \"at\", \"t\", \"te\", \"e\"]):\n",
    "    for j, y in enumerate([\"h\", \"ha\", \"a\", \"at\", \"t\", \"te\", \"e\"]):\n",
    "        attention = math.exp(c[1,i,j].item())\n",
    "        attention_str = str(round(attention,2)) if attention > 0 else \"\"\n",
    "        if i == j:\n",
    "            print(f\"({x:>4} -> {y:>4}) {attention_str:>4}\", end=\" \")\n",
    "        else:\n",
    "            print(f\"[{x:>4} -> {y:>4}] {attention_str:>4}\", end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d3f8295-e89a-4594-8f3f-4aeb53d3c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 1\n",
    "e,la, c = tokenizer.forward(*tokenizer.encode_batch([\"hat\", \"hate\",  \"ab\", \"at\"], M=M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcf1e706-9218-4c59-8ff0-19b95e60bcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(   h ->    h)  1.0 [   h ->    a]  1.0 [   h ->    t]  1.0 [   h ->    e]  1.0 \n",
      "[   a ->    h]  1.0 (   a ->    a)  1.0 [   a ->    t]  1.0 [   a ->    e]  1.0 \n",
      "[   t ->    h]  1.0 [   t ->    a]  1.0 (   t ->    t)  1.0 [   t ->    e]  1.0 \n",
      "[   e ->    h]  1.0 [   e ->    a]  1.0 [   e ->    t]  1.0 (   e ->    e)  1.0 \n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate([\"h\", \"a\", \"t\", \"e\"]):\n",
    "    for j, y in enumerate([\"h\", \"a\",\"t\", \"e\"]):\n",
    "        attention = math.exp(c[1,i,j].item())\n",
    "        attention_str = str(round(attention,2)) if attention > 0 else \"\"\n",
    "        if i == j:\n",
    "            print(f\"({x:>4} -> {y:>4}) {attention_str:>4}\", end=\" \")\n",
    "        else:\n",
    "            print(f\"[{x:>4} -> {y:>4}] {attention_str:>4}\", end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a8041-0e2a-43ad-81bb-eea91fa6f248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4eb9cac-4fab-41a7-8c9d-e79a646784d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fc7147a-7dea-464d-98bb-1618a5e85596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4897503188505912\n"
     ]
    }
   ],
   "source": [
    "s = sum(- x/15 * math.log(x/15) for x in [1,2,3,4,5])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "440c068b-6ee3-4c5a-a5d0-013bd65f8138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07701635339554949"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(1 + math.log(2/3))/9 * (1*3-1*2)  -(1 + math.log(1/3)) / 9 * (0*3 - 1 * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ada3f533-bc9e-4615-b9aa-fb57a9e27983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15403270679109898"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(1 + math.log(1/3))/9 * (1*3-1*1)-(1 + math.log(2/3))/9 * (0*3-1*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fe131b3-f399-435b-9aee-1923f4bacac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6 * 15 * 2 * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bada764-81bf-4fb6-9e2f-aab95ee1cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h ha hat hath a at ath atha t th tha that h ha hat hate a at ate t te e\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27ab93b5-f8d0-4829-b1c5-82a285b061fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 4\n",
    "e,la, c = tokenizer.forward(*tokenizer.encode_packed_batch([[\"hat\", \"hate\", \"ab\", \"at\"]], M=M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b6a5f7d-9a35-4ce1-9dd4-e5ec79bfd2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(   h ->    h)  1.0 [   h ->   ha]      [   h ->  hat]      [   h -> hate]      [   h ->    a] 0.14 [   h ->   at] 0.29 [   h ->  ate] 0.57 [   h -> atea]      [   h ->    t] 0.14 [   h ->   te]      [   h ->  tea]      [   h -> teab]      [   h ->    e] 0.43 \n",
      "[  ha ->    h]      (  ha ->   ha)      [  ha ->  hat]      [  ha -> hate]      [  ha ->    a]      [  ha ->   at]      [  ha ->  ate]      [  ha -> atea]      [  ha ->    t]      [  ha ->   te]      [  ha ->  tea]      [  ha -> teab]      [  ha ->    e]      \n",
      "[ hat ->    h]      [ hat ->   ha]      ( hat ->  hat)  1.0 [ hat -> hate]      [ hat ->    a]      [ hat ->   at]      [ hat ->  ate]      [ hat -> atea]      [ hat ->    t]      [ hat ->   te]      [ hat ->  tea]      [ hat -> teab]      [ hat ->    e]  1.0 \n",
      "[hate ->    h]      [hate ->   ha]      [hate ->  hat]      (hate -> hate)  1.0 [hate ->    a]      [hate ->   at]      [hate ->  ate]      [hate -> atea]      [hate ->    t]      [hate ->   te]      [hate ->  tea]      [hate -> teab]      [hate ->    e]      \n",
      "[   a ->    h]  1.0 [   a ->   ha]      [   a ->  hat]      [   a -> hate]      (   a ->    a)  1.0 [   a ->   at]      [   a ->  ate]      [   a -> atea]      [   a ->    t]  1.0 [   a ->   te]      [   a ->  tea]      [   a -> teab]      [   a ->    e]  1.0 \n",
      "[  at ->    h]  1.0 [  at ->   ha]      [  at ->  hat]      [  at -> hate]      [  at ->    a]      (  at ->   at)  1.0 [  at ->  ate]      [  at -> atea]      [  at ->    t]      [  at ->   te]      [  at ->  tea]      [  at -> teab]      [  at ->    e]  1.0 \n",
      "[ ate ->    h]  1.0 [ ate ->   ha]      [ ate ->  hat]      [ ate -> hate]      [ ate ->    a]      [ ate ->   at]      ( ate ->  ate)  1.0 [ ate -> atea]      [ ate ->    t]      [ ate ->   te]      [ ate ->  tea]      [ ate -> teab]      [ ate ->    e]      \n",
      "[atea ->    h]      [atea ->   ha]      [atea ->  hat]      [atea -> hate]      [atea ->    a]      [atea ->   at]      [atea ->  ate]      (atea -> atea)      [atea ->    t]      [atea ->   te]      [atea ->  tea]      [atea -> teab]      [atea ->    e]      \n",
      "[   t ->    h]  1.0 [   t ->   ha]      [   t ->  hat]      [   t -> hate]      [   t ->    a]  1.0 [   t ->   at]      [   t ->  ate]      [   t -> atea]      (   t ->    t)  1.0 [   t ->   te]      [   t ->  tea]      [   t -> teab]      [   t ->    e]  1.0 \n",
      "[  te ->    h]      [  te ->   ha]      [  te ->  hat]      [  te -> hate]      [  te ->    a]      [  te ->   at]      [  te ->  ate]      [  te -> atea]      [  te ->    t]      (  te ->   te)      [  te ->  tea]      [  te -> teab]      [  te ->    e]      \n",
      "[ tea ->    h]      [ tea ->   ha]      [ tea ->  hat]      [ tea -> hate]      [ tea ->    a]      [ tea ->   at]      [ tea ->  ate]      [ tea -> atea]      [ tea ->    t]      [ tea ->   te]      ( tea ->  tea)      [ tea -> teab]      [ tea ->    e]      \n",
      "[teab ->    h]      [teab ->   ha]      [teab ->  hat]      [teab -> hate]      [teab ->    a]      [teab ->   at]      [teab ->  ate]      [teab -> atea]      [teab ->    t]      [teab ->   te]      [teab ->  tea]      (teab -> teab)      [teab ->    e]      \n",
      "[   e ->    h]  0.5 [   e ->   ha]      [   e ->  hat]  0.5 [   e -> hate]      [   e ->    a] 0.17 [   e ->   at] 0.33 [   e ->  ate]      [   e -> atea]      [   e ->    t] 0.17 [   e ->   te]      [   e ->  tea]      [   e -> teab]      (   e ->    e)  1.0 \n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate([\"h\", \"ha\", \"hat\", \"hate\", \"a\", \"at\", \"ate\", \"atea\", \"t\", \"te\", \"tea\", \"teab\", \"e\"]):\n",
    "    for j, y in enumerate([\"h\", \"ha\", \"hat\", \"hate\", \"a\", \"at\", \"ate\", \"atea\", \"t\", \"te\", \"tea\", \"teab\", \"e\"]):\n",
    "        attention = math.exp(c[0,12+i,12+j].item())\n",
    "        attention_str = str(round(attention,2)) if attention > 0 else \"\"\n",
    "        if i == j:\n",
    "            print(f\"({x:>4} -> {y:>4}) {attention_str:>4}\", end=\" \")\n",
    "        else:\n",
    "            print(f\"[{x:>4} -> {y:>4}] {attention_str:>4}\", end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78a5526e-2422-431d-978d-d92b90c4bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 4\n",
    "e,la, c = tokenizer.forward(*tokenizer.encode_batch([\"hat\", \"hate\",  \"ab\", \"at\"], M=M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c026ebbc-833e-434b-8f48-0e3181b0da0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(   h ->    h)  1.0 [   h ->   ha]      [   h ->  hat]      [   h -> hate]      [   h ->    a] 0.14 [   h ->   at] 0.29 [   h ->  ate] 0.57 [   h ->    t] 0.14 [   h ->   te]      [   h ->    e] 0.43 \n",
      "[  ha ->    h]      (  ha ->   ha)      [  ha ->  hat]      [  ha -> hate]      [  ha ->    a]      [  ha ->   at]      [  ha ->  ate]      [  ha ->    t]      [  ha ->   te]      [  ha ->    e]      \n",
      "[ hat ->    h]      [ hat ->   ha]      ( hat ->  hat)  1.0 [ hat -> hate]      [ hat ->    a]      [ hat ->   at]      [ hat ->  ate]      [ hat ->    t]      [ hat ->   te]      [ hat ->    e]  1.0 \n",
      "[hate ->    h]      [hate ->   ha]      [hate ->  hat]      (hate -> hate)  1.0 [hate ->    a]      [hate ->   at]      [hate ->  ate]      [hate ->    t]      [hate ->   te]      [hate ->    e]      \n",
      "[   a ->    h]  1.0 [   a ->   ha]      [   a ->  hat]      [   a -> hate]      (   a ->    a)  1.0 [   a ->   at]      [   a ->  ate]      [   a ->    t]  1.0 [   a ->   te]      [   a ->    e]  1.0 \n",
      "[  at ->    h]  1.0 [  at ->   ha]      [  at ->  hat]      [  at -> hate]      [  at ->    a]      (  at ->   at)  1.0 [  at ->  ate]      [  at ->    t]      [  at ->   te]      [  at ->    e]  1.0 \n",
      "[ ate ->    h]  1.0 [ ate ->   ha]      [ ate ->  hat]      [ ate -> hate]      [ ate ->    a]      [ ate ->   at]      ( ate ->  ate)  1.0 [ ate ->    t]      [ ate ->   te]      [ ate ->    e]      \n",
      "[   t ->    h]  1.0 [   t ->   ha]      [   t ->  hat]      [   t -> hate]      [   t ->    a]  1.0 [   t ->   at]      [   t ->  ate]      (   t ->    t)  1.0 [   t ->   te]      [   t ->    e]  1.0 \n",
      "[  te ->    h]      [  te ->   ha]      [  te ->  hat]      [  te -> hate]      [  te ->    a]      [  te ->   at]      [  te ->  ate]      [  te ->    t]      (  te ->   te)      [  te ->    e]      \n",
      "[   e ->    h]  0.5 [   e ->   ha]      [   e ->  hat]  0.5 [   e -> hate]      [   e ->    a] 0.17 [   e ->   at] 0.33 [   e ->  ate]      [   e ->    t] 0.17 [   e ->   te]      (   e ->    e)  1.0 \n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate([\"h\", \"ha\", \"hat\", \"hate\", \"a\", \"at\", \"ate\", \"t\", \"te\", \"e\"]):\n",
    "    for j, y in enumerate([\"h\", \"ha\", \"hat\", \"hate\", \"a\", \"at\", \"ate\", \"t\", \"te\", \"e\"]):\n",
    "        attention = math.exp(c[1,i,j].item())\n",
    "        attention_str = str(round(attention,2)) if attention > 0 else \"\"\n",
    "        if i == j:\n",
    "            print(f\"({x:>4} -> {y:>4}) {attention_str:>4}\", end=\" \")\n",
    "        else:\n",
    "            print(f\"[{x:>4} -> {y:>4}] {attention_str:>4}\", end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a245246c-90ea-4368-9771-62130cf9b22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4 * 8 + 3 + 2 + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl22]",
   "language": "python",
   "name": "conda-env-dl22-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
